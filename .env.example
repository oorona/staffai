# .env.example for StaffAI Bot
# Copy to .env and fill in your values
# For production: Use Docker secrets for DISCORD_BOT_TOKEN and LITELLM_API_KEY

# ================================
# DISCORD
# ================================
DISCORD_BOT_TOKEN=your_discord_bot_token_here

# ================================
# LOGGING
# ================================
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL

# ================================
# LITELLM CONFIGURATION
# ================================
LITELLM_API_URL=http://localhost:4000      # Your LiteLLM proxy URL
LITELLM_MODEL=gpt-4o-mini                  # Primary model for conversations & activities
LITELLM_API_KEY=sk-1234                    # API key (use Docker secret in production: /run/secrets/litellm_api_key)

# ================================
# MCP SERVERS (OPTIONAL)
# ================================
MCP_SERVERS=                               # Comma-separated MCP server URLs
                                          # Example: http://mcp-fs:8000,http://mcp-web:8001

# ================================
# BOT BEHAVIOR
# ================================
RESPONSE_CHANCE=0.05                       # Random response probability (0.0-1.0)
RANDOM_RESPONSE_DELIVERY_CHANCE=0.3        # Secondary filter for random responses
MAX_HISTORY_PER_USER=20                    # Max messages in context per user/channel

# ================================
# CONTEXT DECAY (SECONDS)
# ================================
CONTEXT_HISTORY_TTL_SECONDS=1800           # Conversation history TTL (30 min, 0=never)
CONTEXT_MESSAGE_MAX_AGE_SECONDS=1800       # Individual message max age (30 min, 0=no limit)
DEFAULT_CONTEXT_MESSAGES=5                 # Number of recent messages to fetch per user for context (5-10 recommended)

# ================================
# REDIS
# ================================
REDIS_HOST=localhost                       # Use 'redis' for docker-compose
REDIS_PORT=6379
REDIS_DB=0
# REDIS_PASSWORD=                          # Uncomment if Redis requires auth

# ================================
# RATE LIMITING
# ================================
RATE_LIMIT_COUNT=15                        # Max messages per user per window
RATE_LIMIT_WINDOW_SECONDS=60               # Window duration (seconds)
TOKEN_RATE_LIMIT_COUNT=20000               # Max LLM tokens per user per window

# ================================
# RESTRICTION SYSTEM
# ================================
RESTRICTED_USER_ROLE_ID=                   # Role ID assigned when limits exceeded
RESTRICTED_CHANNEL_ID=                     # Channel where restricted users can interact
RESTRICTION_DURATION_SECONDS=86400         # Restriction duration (24 hours)
RESTRICTION_CHECK_INTERVAL_SECONDS=300     # Check interval (5 minutes)

# Notification message templates (use <#{channel_id}> placeholder)
RATE_LIMIT_MESSAGE_USER="You've sent messages too frequently. Please use <#{channel_id}> for bot interactions."
RESTRICTED_CHANNEL_MESSAGE_USER="As a restricted user, please use <#{channel_id}> for bot interactions."

# ================================
# ROLE-BASED ACCESS CONTROL
# ================================
SUPER_ROLE_IDS=                            # Comma-separated role IDs that bypass rate limits and access admin commands
IGNORED_ROLE_IDS=                          # Comma-separated role IDs the bot ignores
DEBUG_CONTEXT_SUPER_USERS=False            # Send debug context info via DM to super users (True/False)

# ================================
# ACTIVITY/PRESENCE
# ================================
ACTIVITY_UPDATE_INTERVAL_SECONDS=300       # Status update frequency (5 min)
ACTIVITY_SCHEDULE_ENABLED=False            # Enable time-based scheduling
ACTIVITY_ACTIVE_START_HOUR_UTC=0           # Active hours start (UTC)
ACTIVITY_ACTIVE_END_HOUR_UTC=23            # Active hours end (UTC)
ACTIVITY_ACTIVE_DAYS_UTC=0,1,2,3,4,5,6     # Active days (0=Mon, 6=Sun)

# ================================
# DAILY TOPIC WORKFLOW
# ================================
DAILY_TOPIC_ENABLED=False                   # Enable admin-approved daily topic threads
DAILY_TOPIC_APPROVAL_CHANNEL_ID=            # Channel ID where "Topic of the day" approval embed is posted
DAILY_TOPIC_PUBLISH_CHANNEL_ID=             # Forum/Media channel ID where approved topic post is created
DAILY_TOPIC_INTERVAL_SECONDS=0              # 0 = daily at approval hour, >0 = interval mode in seconds
DAILY_TOPIC_APPROVAL_HOUR_UTC=8             # In daily mode, proposal appears at/after this UTC hour
DAILY_TOPIC_APPROVAL_TIMEOUT_SECONDS=14400  # Auto-publish timeout (4h by default)
DAILY_TOPIC_CHECK_INTERVAL_SECONDS=60       # Scheduler tick interval
DAILY_TOPIC_THREAD_AUTO_ARCHIVE_MINUTES=1440 # Discord thread auto-archive (60, 1440, 4320, 10080)
DAILY_TOPIC_THREAD_CONTEXT_MESSAGES=40      # Recent thread messages used as context (ignores normal TTL/history rules)

# ================================
# USER MEMORY + LLM CALL AUDIT
# ================================
USER_MEMORY_ENABLED=True                    # Enable personalized per-user memory extraction/injection
USER_MEMORY_ROOT_PATH=data/user_memory      # Disk path for memory files (mounted in docker-compose)
USER_MEMORY_UPDATE_CHANCE=0.25              # Random sampling chance after worthwhile-message filter
USER_MEMORY_MIN_MESSAGE_CHARS=50            # Ignore short messages for memory extraction
USER_MEMORY_MIN_MESSAGE_WORDS=10            # Ignore low-information messages for memory extraction
USER_MEMORY_MAX_CHARS=420                   # Max stored memory size per user
USER_MEMORY_PIPELINE_MODE=tiny_gate_frontier_core # tiny_extract | frontier_pipeline | tiny_gate_frontier_core | disabled
USER_MEMORY_OLLAMA_BASE_URL=http://localhost:11434 # Ollama server URL (location of tiny-model runtime)
USER_MEMORY_OLLAMA_API_KEY=ollama           # API key for Ollama OpenAI-compatible endpoint
USER_MEMORY_OLLAMA_TIMEOUT_S=30             # Timeout (seconds) for tiny-model calls
USER_MEMORY_TINY_MODEL=SmolLM2-1.7B-Instruct # Default tiny model name in Ollama
USER_MEMORY_TINY_MODEL_EXTRACT=             # Optional override model for tiny_extract stage
USER_MEMORY_TINY_MODEL_CLASSIFIER=          # Optional override model for tiny_worthwhile stage
USER_MEMORY_TINY_ACCUMULATE_MAX_TOKENS=4000 # In tiny_extract mode, compact when accumulated memory reaches this token estimate
USER_MEMORY_AUDIT_MAX_ENTRIES=200           # Keep last N user-memory pipeline traces in Redis
USER_MEMORY_DEBUG_CLASSIFICATION=False      # Log detailed memory classification traces (user/message + yes/no)
LLM_CALL_AUDIT_ENABLED=True                 # Save recent LLM interaction payloads to Redis for monitoring
LLM_CALL_AUDIT_MAX_ENTRIES=100              # Keep last N interaction payloads per guild

# ================================
# PROMPT FILES (ADVANCED)
# ================================
# The bot uses TWO system prompts:
# 1. Conversation Prompt (composed): utils/prompts/personality_core_prompt.txt + utils/prompts/personality_prompt.txt
#    - Core rules live in personality_core_prompt.txt
#    - Default persona lives in personality_prompt.txt
#    - Optional per-channel overrides:
#      utils/prompts/channels/<channel_id>/personality_core_prompt.txt
#      utils/prompts/channels/<channel_id>/personality_prompt.txt
# 2. Activity Prompt: utils/prompts/base_activity_system_prompt.txt (configurable below)
#    - Generates bot's Discord presence/activity status
# 3. Daily Topic Prompts (runtime editable):
#      utils/prompts/daily_topic/topic_generation_system_prompt.txt
#      utils/prompts/daily_topic/topic_generation_user_prompt.txt
#      utils/prompts/daily_topic/body_generation_system_prompt.txt
#      utils/prompts/daily_topic/body_generation_user_prompt.txt
#      utils/prompts/daily_topic/topic_generation_response_schema.json
#      utils/prompts/daily_topic/body_generation_response_schema.json
# 4. User Memory prompts/schemas (runtime editable):
#      utils/prompts/user_memory/memory_update_system_prompt.txt
#      utils/prompts/user_memory/memory_update_user_prompt.txt
#      utils/prompts/user_memory/memory_update_response_schema.json
#      utils/prompts/user_memory/tiny_worthwhile_system_prompt.txt
#      utils/prompts/user_memory/tiny_worthwhile_user_prompt.txt
#      utils/prompts/user_memory/tiny_worthwhile_response_schema.json
#      utils/prompts/user_memory/tiny_extract_system_prompt.txt
#      utils/prompts/user_memory/tiny_extract_user_prompt.txt
#      utils/prompts/user_memory/tiny_extract_response_schema.json
#      utils/prompts/user_memory/tiny_compact_system_prompt.txt
#      utils/prompts/user_memory/tiny_compact_user_prompt.txt
#      utils/prompts/user_memory/tiny_compact_response_schema.json
#      utils/prompts/user_memory/frontier_core_extract_system_prompt.txt
#      utils/prompts/user_memory/frontier_core_extract_user_prompt.txt
#      utils/prompts/user_memory/frontier_core_extract_response_schema.json
BASE_ACTIVITY_SYSTEM_PROMPT_PATH=utils/prompts/base_activity_system_prompt.txt

# ================================
# TOKEN CONSUMPTION STATS & REPORTING
# ================================
STATS_REPORT_CHANNEL_ID=                   # Channel ID for automated token usage reports
STATS_REPORT_INTERVAL_SECONDS=86400        # Report frequency (24 hours default)
STATS_REPORT_TOP_USERS=10                  # Number of top users to show in reports
