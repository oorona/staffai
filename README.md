# StaffAI â€” Intelligent Discord AI Agent

A production-grade Discord bot showcasing advanced **Large Language Model (LLM) integration**, **agentic tool calling**, and **intelligent conversation management**. Built to demonstrate deep expertise in AI systems architecture, prompt engineering, and real-time conversational AI deployment.

---

## ğŸ§  AI & Machine Learning Capabilities

### LLM Integration & Inference Pipeline

**Universal Model Gateway Architecture**
- **LiteLLM Proxy Integration** â€” Abstraction layer enabling seamless switching between 100+ LLM providers (OpenAI GPT-4/5, Anthropic Claude, Google Gemini, Azure OpenAI, local models via Ollama/LM Studio)
- **Provider-Agnostic Design** â€” Hot-swappable model configuration without code modifications, enabling rapid A/B testing and cost optimization
- **Structured Output Enforcement** â€” JSON Schema validation guaranteeing zero parsing errors through response format constraints
- **Temperature & Sampling Control** â€” Model-specific temperature tuning with automatic GPT-5 temperature normalization

**Response Type Classification**
```
text   â†’ Natural language conversation
url    â†’ Contextual link sharing with descriptions
gif    â†’ Animated response via Tenor/Giphy MCP integration
latex  â†’ Mathematical formula rendering (LaTeX â†’ PNG pipeline)
code   â†’ Syntax-highlighted code blocks
output â†’ Command execution results
```

### Model Context Protocol (MCP) Tool Calling

**Agentic Function Calling Architecture**
- **Dynamic Tool Discovery** â€” Runtime tool schema fetching from HTTP MCP servers using FastMCP client
- **http-streamable Transport** â€” Modern streaming protocol (superseding SSE) for efficient tool communication
- **Schema Translation Pipeline** â€” Automatic conversion from FastMCP format to OpenAI function-calling format
- **Session-Level Tool Caching** â€” One-time tool loading at bot initialization for sub-100ms tool availability

**Intelligent Tool Invocation**
- **Keyword-Based Tool Routing** â€” NLP-driven detection of tool-relevant keywords (multilingual: English/Spanish)
- **Three-Path Response Handling**:
  1. **Tool Execution Path** â€” LLM requests tool â†’ MCP execution â†’ Result injection â†’ Final structured response
  2. **Tool Declination Path** â€” Tools available but unused â†’ Forced structured output via second inference call
  3. **Direct Response Path** â€” No tools applicable â†’ Single-pass structured generation
- **Error Resilience** â€” 10-second timeout per server, automatic retry after 15-minute cooldown, partial failure isolation

### Intelligent Context Management

**Per-User/Per-Channel Conversational Memory**
- **Redis-Backed Persistence** â€” Conversation history survives bot restarts with configurable TTL
- **Time-Based Context Decay** â€” Dual expiration mechanism:
  - **History TTL** â€” Entire conversation window expiry (default: 30 minutes)
  - **Message Age Filtering** â€” Individual message staleness detection and pruning
- **Context Window Optimization** â€” Configurable max history (default: 20 messages) preventing context overflow

**Scenario-Aware Context Injection**
| Trigger | Context Strategy |
|---------|------------------|
| @Mention | User-bot history only |
| Reply to Bot | User-bot history only |
| Tag Bot on Reply to Other User | Inject referenced message context |
| Random Response | Fetch 5-10 recent channel messages |

### Natural Language Understanding Features

**Automatic Language Detection**
- **Bilingual Response Generation** â€” Automatic language matching (Spanish primary, English supported)
- **Personality-Driven Prompt Engineering** â€” Character consistency maintained across language switches
- **Response Length Optimization** â€” â‰¤30 word constraint for conversational naturalness

**Contextual Random Engagement**
- **Channel Awareness** â€” Fetches and analyzes recent conversation for contextually relevant interjections
- **Dual-Probability Gating** â€” Two-stage probability filter preventing response spam
- **Organic Conversation Flow** â€” LLM-generated responses that match ongoing discussion tone

### LLM-Generated Dynamic Presence

**Autonomous Status Generation**
- **LLM-Powered Activity Text** â€” Bot presence/status text generated by the LLM itself
- **Activity Type Rotation** â€” Cycles through Playing/Listening/Watching/Custom states
- **Time-Based Scheduling** â€” Configurable active hours (UTC) and weekday restrictions
- **Mood-Aware Presence** â€” Status reflects contextual "personality" state

### Token Consumption Analytics

**Usage Tracking & Cost Attribution**
- **Real-Time Token Metering** â€” Per-user, per-guild token consumption tracking
- **Model-Specific Cost Calculation** â€” Support for Gemini, OpenAI, XAI, and Anthropic pricing tiers
- **Automated Reporting** â€” Scheduled top-N user reports with cost estimates
- **Admin Dashboard Command** â€” `/tokenstats` for detailed user consumption analysis

### Multi-Modal Response Rendering

**Response Type Processors**
- **LaTeX Pipeline** â€” Mathematical formula rendering via external API â†’ PNG embedding
- **Code Highlighting** â€” Syntax-aware Discord code block formatting
- **GIF Integration** â€” MCP-powered animated response retrieval
- **URL Enrichment** â€” Link sharing with contextual descriptions

---

## ğŸ›¡ï¸ Protection & Rate Limiting Systems

**Dual-Tier Rate Limiting**
- **Message Count Limiting** â€” Sliding window implementation via Redis lists
- **Token Consumption Limiting** â€” Prevents expensive API abuse through usage caps

**Automatic Restriction System**
- **Role-Based Restriction** â€” Automatic "Restricted User" role assignment on limit breach
- **Channel Isolation** â€” Restricted users directed to designated interaction channel
- **Auto-Expiry** â€” Background task removes restrictions after configurable duration

**Access Control**
- **Super User Bypass** â€” Configurable roles exempt from all limits
- **Ignored Roles** â€” Bot completely ignores messages from specified roles

---

## ğŸ“š Documentation

| Document | Description |
|----------|-------------|
| [Installation Guide](docs/INSTALLATION.md) | Prerequisites, dependencies, and setup instructions |
| [Configuration Reference](docs/CONFIGURATION.md) | Environment variables and settings |
| [Architecture Overview](docs/ARCHITECTURE.md) | Technical deep-dive into project structure |
| [Project Specifications](specs/specs.txt) | Complete technical specifications |

---

## ğŸ”§ Technology Stack

| Category | Technologies |
|----------|--------------|
| **AI/ML** | LiteLLM, OpenAI API, FastMCP, Model Context Protocol |
| **Runtime** | Python 3.8+, asyncio, Discord.py 2.3+ |
| **Data** | Redis 5.0+ (persistence, rate limiting, analytics) |
| **Deployment** | Docker, Docker Compose |
| **Protocols** | HTTP Streamable Transport, JSON Schema |

---

## ğŸ“„ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **LiteLLM** by BerriAI â€” Universal LLM gateway
- **Discord.py** by Rapptz â€” Discord API wrapper
- **FastMCP** by jlowin â€” Model Context Protocol client
- **Redis** by Redis Ltd. â€” In-memory data structure store
