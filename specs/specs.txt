# specs.txt - Detailed Project Specifications for StaffAI Enhanced Bot

## 1. Project Goal
To create a configurable, interactive Discord bot that leverages an external LLM API (OpenWebUI compatible) for generating responses.
The bot should manage conversation context persistently (per user per channel), enforce usage limits through rate-limiting (messages and tokens) and role restrictions, allow exemptions, ignore specific roles, and provide clear notifications, all while being configurable via environment variables and deployable via Docker.
It should also support automatic timed removal of restrictions.

## 2. Core Technologies
- Python: 3.8+
- Libraries:
    - discord.py: >=2.3.0 (Core Discord interaction)
    - python-dotenv: >=1.0.0 (Loading .env files)
    - aiohttp: >=3.9.0 (Async HTTP requests for LLM API)
    - redis: >=5.0.0 (Connecting to Redis for persistence and rate limiting)
    - tiktoken: >=0.5.0 (Token counting for LLM interactions)
- External Services:
    - Discord API
    - OpenWebUI Compatible LLM API (e.g., Ollama, LM Studio, vLLM)
    - Redis Server (v5.0+)
- Deployment: 
Docker, Docker Compose

## 3. Discord Intents & Permissions

### Intents
(Enabled in Discord Dev Portal & Code)
- `Guilds`: Basic server information and events.
- `Members (Privileged)`: Required for `on_member_join` and accessing member roles reliably, and for restriction removal task.
- `Message Content (Privileged)`: Required to read message content for processing.
### Bot Permissions (Required Role Permissions in Server)
- `View Channel`: See channels and read messages.
- `Send Messages`: Send replies, notifications.
- `Manage Roles`: Add/remove the `RESTRICTED_USER_ROLE_ID`.
Bot role must be higher than the restricted role.
- `Read Message History`: Needed to resolve message references for replies.
## 4. Configuration (`.env` Variables)

All configurations are managed via an `.env` file in the project root.
- `DISCORD_BOT_TOKEN`: (Required) Your Discord bot token.
- `LOG_LEVEL`: (Optional, Default: INFO) Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL).
- `OPENWEBUI_API_URL`: (Required) Base URL of the LLM API endpoint (e.g., http://host.docker.internal:8080).
- `OPENWEBUI_MODEL`: (Required) Name of the model to use via the API (e.g., llama3:latest).
- `OPENWEBUI_API_KEY`: (Optional) Bearer token API key if the endpoint requires authentication.
- `RESTRICTED_CHANNEL_ID`: (Required for restriction) ID of the channel where restricted users must interact. If unset, channel enforcement disabled.
- `RESPONSE_CHANCE`: (Optional, Default: 0.05) Float between 0.0 and 1.0 representing the random chance the bot responds to a non-mention/non-reply message.
- `MAX_HISTORY_PER_USER`: (Optional, Default: 20) Max number of message *pairs* (user+assistant) stored per user/channel context in Redis by `WebUIAPI`.
- `REDIS_HOST`: (Required for persistence/rate limits, Default: localhost) Hostname/IP of Redis server.
Use 'redis' if using the default docker-compose service name.
- `REDIS_PORT`: (Optional, Default: 6379) Port of Redis server.
- `REDIS_DB`: (Optional, Default: 0) Redis database number for operational data (history via `WebUIAPI`, and rate limits, restriction expiry via the bot's general Redis client). `main.py` currently passes this same DB config for both purposes.
- `REDIS_PASSWORD`: (Optional) Password for Redis authentication.
- `REDIS_DB_TEST`: (Optional, Default: 9) Redis database number used ONLY when running tests in `utils/webui_api.py`. (This applies if tests directly instantiate `WebUIAPI` with a test-specific config).
- `IGNORED_ROLE_IDS`: (Optional) Comma-separated list of Role IDs. Bot will ignore all messages from users with any of these roles.
- `RATE_LIMIT_COUNT`: (Optional, Default: 15) Max number of *interacting* messages per user per window before restriction.
- `RATE_LIMIT_WINDOW_SECONDS`: (Optional, Default: 60) Time window (seconds) for message and token rate limits.
- `TOKEN_RATE_LIMIT_COUNT`: (Optional, Default: 20000) Max total LLM tokens (prompt+completion) per user per window before restriction.
- `RESTRICTED_USER_ROLE_ID`: (Required for restriction) ID of the role assigned when limits are hit. MUST be created manually in Discord.
If unset, restriction system disabled.
- `RATE_LIMIT_MESSAGE_USER`: (Optional, Default: Provided) Message template sent when rate limit is hit. Maps to `rate_limit_message_user_template` in bot code.
`<#{channel_id}>` is replaced. Notification may be suppressed if restriction was triggered by a "Random Chance" interaction.
- `RESTRICTED_CHANNEL_MESSAGE_USER`: (Optional, Default: Provided) Message template sent when restricted user talks outside the allowed channel. Maps to `restricted_channel_message_user_template` in bot code.
`<#{channel_id}>` is replaced.
- `RATE_LIMIT_EXEMPT_ROLE_IDS`: (Optional) Comma-separated list of Role IDs. Users with these roles bypass all rate limits.
- `LIST_TOOLS`: (Optional) Comma-separated list of tool IDs for the LLM API (if supported).
- `KNOWLEDGE_ID`: (Optional) ID of knowledge base collection for the LLM API (if supported).
- `RESTRICTION_DURATION_SECONDS`: (Optional, Default: 86400) Duration in seconds for how long the restricted role should be applied.
If 0 or not set, the role remains indefinitely (manual removal required).
- `RESTRICTION_CHECK_INTERVAL_SECONDS`: (Optional, Default: 300) How often (in seconds) the bot checks for expired restrictions.
Must be > 0 if `RESTRICTION_DURATION_SECONDS` > 0.

## 5. File Structure

```
staffai/
├── .env
├── Dockerfile
├── docker-compose.yaml
├── main.py
├── bot.py
├── requirements.txt
├── README.md
├── specs.txt  &lt;-- This file
├── bot.log
│
├── cogs/
│   └── listener_cog.py
│
└── utils/
├── webui_api.py
├── message_handler.py  # NEW: Handles message processing logic
├── prompts/
│   ├── personality_prompt.txt
└── (optional test scripts)
```
## 6. Core Logic - `main.py`
- Sets up logging based on `LOG_LEVEL`.
- Loads all environment variables from `.env`.
- Performs validation checks for critical variables; exits if invalid.
- Loads prompt content from `utils/prompts/`.
- Parses configurations (e.g., splitting comma-separated IDs, converting types).
- Constructs a single `redis_connection_config` dictionary from Redis environment variables.
- Instantiates `AIBot`, passing all configuration values. This includes passing the `redis_connection_config` to both `redis_config` (for `WebUIAPI` history) and `general_redis_config` (for the bot's general Redis client used for rate limits and restriction expiry).
- Contains `main_run()` function to start the bot, handling login/intent errors.
- Entry point (`if __name__ == "__main__":`) calls `main_run()`.

## 7. Core Logic - `bot.py` (`AIBot` class)
- Subclasses `discord.ext.commands.Bot`.
- `__init__`: 
    - Accepts all configuration parameters from `main.py`.
    - Stores parameters like `self.restricted_user_role_id`, `self.restriction_duration_seconds`, etc.
    - **NEW**: Accepts `redis_config` (for `WebUIAPI`) and `general_redis_config`.
    - **NEW**: Instantiates and stores `self.api_client = WebUIAPI(...)`, passing `redis_config` to it.
- Initializes `self.ignored_role_ids_set` and `self.rate_limit_exempt_role_ids_set` as sets.
    - **NEW**: Initializes a general-purpose Redis client (`self.redis_client_general`) using `general_redis_config` if provided. This client is used by `MessageHandler` and `ListenerCog` for rate limits and restriction expiry.
- `setup_hook`: Asynchronously loads extensions (currently `cogs.listener_cog`).
- `on_ready`: Logs bot readiness.

## 8. Core Logic - `utils/webui_api.py` (`WebUIAPI` class)
- Handles communication with the LLM API and Redis history persistence.
- **NEW**: Instantiated by `AIBot` and accessed via `bot.api_client`.
- `__init__`: Takes API details, prompt content, and `redis_config` for its dedicated history Redis client.
- `get_context_history` / `save_context_history`: Manage conversation history in Redis (e.g., `discord_context:{user_id}:{channel_id}`).
- `generate_response`: Constructs payload, calls LLM, processes response, returns content/error/tokens. Does NOT save history itself.
- Includes token counting utilities (`tiktoken`).

## 9. Core Logic - `utils/message_handler.py` (`MessageHandler` class) - NEW SECTION
- Purpose: Encapsulates the primary decision-making logic for incoming messages, previously in `ListenerCog.on_message`.
- `__init__`: Takes `bot_instance: AIBot` and `message: discord.Message`. Gets access to `bot.api_client`, `bot.redis_client_general`, and bot configurations.
- `MessageHandlerResult` (TypedDict): Defines the structured result returned by `process()`, indicating the action the cog should take (e.g., "reply", "apply_restriction", "do_nothing") and associated data.
- `async process()`: Main public method. Orchestrates the following:
    1.  Initial filtering (e.g., ignored roles).
    2.  **Engagement Logic (`_determine_engagement`)**: Determines if the bot should respond (mention, reply, random chance) and identifies the `interaction_case_debug`.
    3.  **Restricted User Channel Enforcement (`_check_channel_restrictions`)**: If bot should respond and user is restricted + in wrong channel, returns result to notify.
    4.  **Message Rate Limiting (`_check_message_rate_limit`)**: If applicable and limit hit, returns result to apply restriction, including `triggering_interaction_case`.
    5.  **LLM Interaction (`_handle_llm_interaction`)**: If proceeding:
        - Manages `message.channel.typing()` context.
        - Prepares LLM context (history from `bot.api_client`, `extra_assistant_context` based on `interaction_case_debug`).
        - Calls `bot.api_client.generate_response()`.
        - If successful, saves history using `bot.api_client.save_context_history()`.
        - **Token Rate Limiting (`_check_token_rate_limit`)**: After a successful LLM response, checks token usage. If limit hit, returns result to apply restriction, including `triggering_interaction_case`.
        - If no rate limits hit by tokens, returns result to reply with LLM content.
        - Handles API errors and returns appropriate error result.
- Helper methods (e.g., `_determine_engagement`, `_check_channel_restrictions`, `_check_message_rate_limit`, `_handle_llm_interaction`, `_check_token_rate_limit`) encapsulate specific logic steps.

## 10. Core Logic - `cogs/listener_cog.py` (`ListenerCog` class)
- Handles Discord events and interacts with `MessageHandler`.
Uses `discord.ext.tasks` for periodic checks.
- `__init__`: Gets `bot` instance. **NEW**: Does not instantiate `WebUIAPI`. Gets reference to `bot.redis_client_general`. Starts `check_restrictions_loop` based on bot config and Redis availability.
- `on_message`:
    - Performs minimal initial checks (self, other bots, DMs, ensures author is `discord.Member`).
    - **NEW**: Instantiates `MessageHandler(self.bot, message)`.
    - **NEW**: Calls `result = await handler.process()`.
    - **NEW**: Based on `result.action` from `MessageHandlerResult`:
        - If "reply": Sends the `result.content`.
        - If "notify_restricted_channel": Sends the `result.content`.
        - If "apply_restriction": Calls `self._apply_restriction()`. If restriction applied, sends notification BUT **suppresses notification if `result.triggering_interaction_case` was "Random Chance"**.
        - If "error": Sends error feedback.
        - If "do_nothing": Takes no further action.
- **Restricted User Channel Enforcement**: Now handled by `MessageHandler`.
- **Rate Limiting**: Logic now primarily within `MessageHandler`. Cog acts on `MessageHandler`'s decision to restrict.
- **Context Injection Logic**: Now handled by `MessageHandler`.
- **LLM Call**: Now handled by `MessageHandler`.
- **History Saving**: Now handled by `MessageHandler`.
- **Token Rate Limit Application**: Now handled by `MessageHandler` after LLM response. Cog acts on decision.
- `_apply_restriction` (Helper): Remains in cog. Adds `RESTRICTED_USER_ROLE_ID`. Sets expiry timestamp in Redis using `bot.redis_client_general` if configured.
- `check_restrictions_loop` (Background Task):
    - Uses `bot.redis_client_general` to scan for `restricted_until:{guild_id}:{user_id}` keys.
    - Includes enhanced logging for current time, expiry time, remaining duration, and decisions per key.
- Runs only if `bot.restriction_duration_seconds > 0`, role ID set, and `bot.redis_client_general` is available.
    - Logic for removing roles, deleting keys, and error handling remains.
- Includes `@check_restrictions_loop.before_loop` for `await bot.wait_until_ready()`.

## 12. Docker Setup
- (No changes for these features, relies on `.env` file for new variables if any were added, though current refactor mainly changes code structure).

## 13. Redis Data Structures (Examples)
- `discord_context:{user_id}:{channel_id}` (STRING): Stores JSON conversation history.
Managed by `WebUIAPI` (via `AIBot.api_client`).
- `msg_rl:{guild_id}:{user_id}` (LIST): Timestamps for message rate limit.
Managed by `MessageHandler` using `AIBot.redis_client_general`. TTL set.
- `token_rl:{guild_id}:{user_id}` (LIST): "timestamp:token_count" for token rate limit.
Managed by `MessageHandler` using `AIBot.redis_client_general`. TTL set.
- `restricted_until:{guild_id}:{user_id}` (STRING): **NEW** (already specified, but re-confirming). UNIX timestamp for restriction expiry.
Set by `ListenerCog._apply_restriction` using `AIBot.redis_client_general`.
Read and deleted by `ListenerCog.check_restrictions_loop`. Redis key TTL also set.
